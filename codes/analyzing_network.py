#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 29 16:15:17 2022

@author: Swapnil Keshari

"""

#%% Importing Libraries
import networkx as nx
import pandas as pd
import sys, getopt
import os

def clean_data(df,column_name):
    df[column_name]=df[column_name].replace('congo.republic','republic_of_the_congo.republic', regex=True)
    df[column_name]=df[column_name].replace('congo.kinshasa','dr_congo.kinshasa', regex=True)
    df[column_name]=df[column_name].replace('congo.lubumbashi','dr_congo.lubumbashi', regex=True)
    df[column_name]=df[column_name].replace('india.indianapolis','usa.indianapolis', regex=True)
    df[column_name]=df[column_name].replace('simne_d..sun','simne_d.sun', regex=True)
    df[column_name]=df[column_name].replace('brian_d..goudy','brian_d.goudy', regex=True)
    return df

def process_country(df):
    df=df.rename(columns={0:"first",1:"last",2:"country",3:"city"})
    df['country']=df['country'].str.replace('_',' ')
    df["country"]=df["country"].replace('usa', 'united states')
    # Changing to countries recognized by UN
    df["country"]=df["country"].replace('taiwan', 'china')
    return df

def parse_args(argv):
    try:
        opts, args = getopt.getopt(argv,"y:p:",["year=","path="])
    except getopt.GetoptError:
        print("Recheck the format of input arguments given")
        sys.exit(2)
    for opt, arg in opts:
        if opt in ("-p", "--path"):
            path1 = arg
        elif opt in ("-y", "--year"):
            year1 = arg
    return year1,path1    
#%% Reading the data
year,path = parse_args(sys.argv[1:])
print(year,path)
os.chdir(path)
countrycontinent=pd.read_csv("../input/countryContinentMapping.csv",header=0,sep=',')
edgelist=pd.read_csv("../input/"+year+"_edge_list_3.csv",header=0,sep=',',index_col=0)
authorlist=pd.read_csv("../input/"+year+"_author_list_3.csv",header=0,sep=',',index_col=0)
#%% Processing the country (Especially congo)
edgelist=clean_data(edgelist,'author1')
edgelist=clean_data(edgelist,'author2')
authorlist=clean_data(authorlist,'author')
#%% Generating the network
COA=nx.Graph()
# Making the edgelist tuple and adding edges
edgetuple=list(zip(edgelist['author1'],edgelist['author2']))
COA.add_edges_from(edgetuple)
#%%
"""
We will now be using network properties
1) creating the edge and the authorlist from the graph
2) mapping the authors to the continent and creating continent table
"""
#%% Generating edges from the developed graph
grauthlist = pd.DataFrame(list(COA.nodes), columns =['author']) 
gredgelist = nx.to_pandas_edgelist(COA)
gredgelist['edgenumber']=gredgelist.index
#Comparing the length of author list generated by Eunseo and Generated in networkx
assert len(authorlist)==len(set(pd.concat([gredgelist['source'], gredgelist['target']])))
assert len(edgelist)==len(gredgelist)
#%% Generating degree distribution from graph and appending it to authors
grauthlist=pd.merge(grauthlist, authorlist, on='author')
degreedist = pd.DataFrame(dict(DEGREE = dict(COA.degree)))
degreedist['author']=degreedist.index
grauthlist=grauthlist.sort_values(by=['author'])
grauthlist=pd.merge(grauthlist, degreedist, on='author')
#%% Generating edge wise author list
#generating author list from graph developed using networkx
#Replacing taiwan by china
grauthlist = pd.concat([grauthlist, grauthlist['author'].str.split('.',expand=True)], axis=1)
origauthor=gredgelist['source'].str.split('.',expand=True)
termauthor=gredgelist['target'].str.split('.',expand=True)

grauthlist=process_country(grauthlist)
origauthor=process_country(origauthor)
termauthor=process_country(termauthor)

origauthor['source']=gredgelist['source']
origauthor['edgenumber']=gredgelist['edgenumber']

termauthor['target']=gredgelist['target']
termauthor['edgenumber']=gredgelist['edgenumber']
#%% Mapping the country to continent.
countrycontinent["country"]=countrycontinent["country"].str.lower() 
countrycontinent["continent"]=countrycontinent["continent"].str.lower()

grauthlist=pd.merge(grauthlist, countrycontinent, on='country')
contorigauthor=(pd.merge(origauthor, countrycontinent, on='country')).sort_values(by='edgenumber').reset_index(drop=True)
conttermauthor=(pd.merge(termauthor, countrycontinent, on='country')).sort_values(by='edgenumber').reset_index(drop=True)
#Checking if all the countries are mapped
assert len(contorigauthor)== len(origauthor)
assert len(conttermauthor)== len(termauthor)
#%% Appending nodebetweenness centrality to authorlist
node_betweenness=pd.read_csv("../output/{}/{}_node_betweeness.txt".format(year,year),sep='\t')
node_betweenness.rename(columns = {'Unnamed: 0':'author','0':'nodebetweenness'}, inplace = True)
grauthlist=grauthlist.merge(node_betweenness,on='author')
assert grauthlist.nodebetweenness.isna().sum() == 0
#%% Writing the continent mapped author list for the network
grauthlist['year']=year
grauthlist.to_csv("../output/"+year+"/"+year+'_all_mapped_author_list.txt',sep='\t',index=False)
conttermauthor=conttermauthor.rename(columns={'country':'country1'})
## Edge list required to build country collaboration graph
gredgelist=pd.concat([contorigauthor, conttermauthor], axis=1)
gredgelist['year']=year
gredgelist.to_csv("../output/"+year+"/"+year+'_all_mapped_edge_list.txt',sep='\t',index=False)
#%% Writing country fraction
''' Figure 1d-- country wise fraction counts'''
countryfraction=grauthlist.groupby(['country']).sum()['count']*100/(grauthlist['count'].sum())
countryfraction.to_csv("../output/"+year+"/"+year+'_all_country_fraction.txt',sep='\t',index=True)
#%% Some important numbers from the mapped author list
print("Total counts in "+year+" = "+str(grauthlist['count'].sum()))
print("Unique countries in "+year+" = "+str(len(grauthlist['country'].unique())))
#%% Finding the largest connected component of the graph
largest_cc = max(nx.connected_components(COA), key=len)
largest_graph = COA.subgraph(largest_cc).copy()
lccauthlist = pd.DataFrame(list(largest_graph.nodes), columns =['author'])
lccauthlist = grauthlist[grauthlist['author'].isin(list(lccauthlist['author']))]
lccauthlist.to_csv("../output/"+year+"/"+year+'_lcc_mapped_author_list.txt',sep='\t',index=False)
print("Curated author lists. Done!!")
## Uncomment to look at mapped edge list
# lccedgelist = nx.to_pandas_edgelist(largest_graph)
# lccedgelist.to_csv("output/"+year+"/"+year+'_lcc_mapped_edge_list.txt',sep='\t',index=False)